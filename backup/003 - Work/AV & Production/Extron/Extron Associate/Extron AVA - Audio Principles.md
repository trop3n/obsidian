
## Overview

> With the abundance of technology and its ease of accessibility today, the AV industry continuously strives to promote and support the everchanging capabilities of audio systems. Creating and troubleshooting an effective listening environment can be difficult without a basic understanding of sound and audio.

This course will examine the basics of sound, how it is created and manipulated to create audio in an AV system, and how Extron reinforces these advancements with it's audio solutions.
## Objectives

Upon completion of this course, you will be able to:

- Differentiate between working with audio, and working with sound
- Recognize the properties of sound and how it propagates
- Understand the properties of sound within the acoustic domain
- Differentiate between analog and digital audio signals
- Identify various audio devices and how audio signals are transmitted
- Understand the importance of signal processing capabilities
- Identify the various types of audio amplifiers and speakers and how they operate
- Recognize the standards organizations that develop guidelines for audio systems
- Identify the various audio file formats
### Translating Sound vs. Audio

> Working with audio involves working with sound. To some, this concept could be recognized as one in the same. To others, it's all about the audio signal path, how the sound was created or captured, the mixing, processing, amplification and distribution of the signal. 

Let's take a closer look at how sound and audio differ.
#### What is Sound?

> Sound it a type of kinetic energy that refers to the vibrations caused by a source. These vibrations propagate as sound waves, travelling through the air or other medium (solid, liquid). Sound is the reception of such waves and their perception by the brain as the acoustical meaning. 

- For example, I hear a beeping sound.
#### What is Audio?

> Audio is a more technical term, referring to the reproduction of sound as an electrical signal coming from a recording or electronic device. For example, I hear beeping in the audio.
### Acoustics

> Fundamentally, sound starts acoustically, which is the science or study of sound, how it's created, it's ability to travel within a space, and the way it's managed.

Another aspect is the understanding of human hearing, and how everyone perceives sound differently. 

This is critical in how we work with it, all starting with the ear. 

Let's review the anatomy of how we hear. The ear is a very senstive organ, responsible for sensing sound and maintaining equilibrium. It is divided into three parts: the outer ear, the middle ear, and the inner ear.
#### Outer Ear

> The outer ear is the visible portion that collects vibrations in air pressure. Sound funnels into the ear canal towards the eardrum.
#### Middle Ear

> The middle ear starts at the eardrum, which is a membrane similar to a microphone. When sound vibrations cause the eardrum to move, this action is transferred to the inner ear. 
#### Inner Ear

> The inner ear consists of the **cochlea**, a spiral-shaped cavity that passes sound pressure patterns to the brain as electrical nerve impulses, where they are interpreted as sounds.
### Training our Ears

> It is possible to train our ears using many different methods. Listening to music is one example of how we can train our ability to hear the subtleties in a song. 

The scientific study of how humans perceive various sounds is known as ***Psychoacoustics***. 

- This involves the process to gain awareness of sound quality through listening experience, to hear the different frequency levels and ranges.
- However, it may be difficult to identify the instruments, sound effects or possibly solve specific issues without some guidance.
#### Perceived Listening

***Perceived Listening*** is when sound waves travelling through the air arrive at the ear. Within the ear it is transformed into nerve pulses that travel to the brain, and what the person hears is perceived. 
#### Critical Listening

***Critical Listening*** is an engineering point of view, for technical and physical aspects of sound, music, frequency, range and pitch. This helps in how sounds are blended together, and the ability to make adjustments.
#### Objective / Subjective Listening

The tone or meaning of a sound can be evaluated differently. For example, one piece of audio may be more subdued vs. another that is up-tempo or louder.

***Objective Listening*** is a neutral and unbiased evaluation that takes facts and measurements into consideration without influence from personal bias. 

***Subjective Listening*** is an evaluation that does induce the listener's personal bias, but may not lend to verified facts and measurements.
## How to Sounds Propagate?

As noted, sound is created by vibrations that travel in a wave through a medium from one location to another. The source that creates the disturbance could be the vocal cords of a person, or the strings of a guitar. 

Regardless of what the object is, the rise in sound level creates a positive pressure wave of air molecules. This region of high sound pressure is called a ***compression***.

The corresponding drop in sound level results in less wave pressure. This low sound region is called a ***rarefaction***. Successive pressure waves of compression, followed by rarefactions constitute a continuously perceived sound level. 

It is important to remember that in a sound wave, the particles move back and forth rather than up and own. The wavelength is simply the length of one complete wave cycle. Since a wave repeats its pattern, the length of one complete wave cycle is measured as the distance from crest to crest or from trough to trough. 
### Sound Waves

How do sounds propagate? If we think of a wave spreading out from a rock thrown into a pond, the circle, or ripple, formed by the wave moves further away from the source. Energy loss will occur as the circle grows and spreads out. Therefore, the height of the wave (amplitude) becomes smaller, and finally decreases to 0 or nothing.
### The Behavior of Sound Waves

> Similarly, sound reacts the same way as the ripple and will eventually dissapate. 

Unless it reaches the end of a medium or encounters an obstacle in it's path, sound doesn't just stop. Rather, it undergoes certain behaviors where any of the following factors could occur, and affect the sound quality. 

- ***Reflection***: Sound waves hitting a surface and bouncing off
- ***Diffraction***: Sound waves bending around an object
- ***Refraction***: A change in the direction of waves as they pass through an object
- ***Absorption***: Some or all the waves are stopped within the material
- ***Diffusion***: The scattering of sound after reflecting off an irregular service
- ***Resonance***: The vibration of an object or space at a certain frequency
- ***Phase***: The time-based difference of wave forms, either acoustical or electrical
### The Speed of Sound

> As sound disperses, it travels through a medium of particle to particle interaction. How fast? The speed of any wave depends on the properties of the medium through which the wave is travelling.

As one particle becomes disturbed, it exerts a force to the next adjacent particle, thus disturbing from rest and transporting the energy through the medium. 

Therefore, the speed of a sound refers to how fast the disturbance is passed from particle to particle. 

Sound travels at different speeds in different media. The speed of sound travelling in air depends upon the properties of the air, the temperature, and humidity. 

At sea level, with a temperature of 70 degress Fahrenheit (20 degrees Celcius), and under normal atmospheric conditions, the speed of sound is 1228 feet (343 meters) per second. 

- However, changes in temperature, humidity and the medium through which sound travels will affect the speed.
### Sound Levels

> Sounds are often characterized as to how humans perceive them. These sound perceptions are high-pitched or low-pitched; loud or soft. 

On the other hand, sound levels can be accurately identified and measured using instruments to describe the physical characteristics.
#### Frequency

***Frequency*** is defined as the rate of repetition of a regular event. Sound wave vibrations are carried out as a repeating pattern, where on such repetition is one wave cycle. The frequency of a vibration is expressed in Hertz (Hz) where 1 Hz = 1 vibration, or 1 cycle per second.

Vibrations at frequencies between 20 to 20,000 are generally capable of being detected by the human ear. 

The sensation of a frequency is commonly referred to as the ***pitch*** of a sound. A high pitch sound corresponds to high frequency sound waves, and a low pitch sounds correspond to low frequency sound waves. 
#### Amplitude

Sounds often characterized as to how humans perceive them. These sounds perceptions are high-pitched or low-pitched; loud or soft. On the other hand, sound levels can be accurately identified and measured using instruments to describe the physical characteristics.

The ***Amplitude*** of a wave is related to the amount of energy it carries. Increasing the amplitude of a sound is making it louder, for example turning up the volume. While decreasing the amplitude makes the sound softer, such as turning down the volume. The amplitude can be measured from the rest position to the crest position, or similarly from rest to the trough position.
#### Decibel

> The unit for sound intensity is the bel, named in honor of *Alexander Graham Bell*, the inventor of the telephone. Humans can detect sound changes at one tenth or "deci" of a bel. 

Therefore, the logarithmic ratio to measure the change in sound intensity or electric signals are called **Decibels (dB)**.

The higher the decibel level, the louder the sound. 0 dB is the threshold of hearing or the lowest pressure the human ear can hear. 120 dB is the threshold of pain or the highest-pressure level the human ear can tolerate before damage occurs.
# Audio Signals

> The part of a sound system that is most obvious are probably the loudspeakers that produce the sounds that we hear. But actually, the speaker system is last in a chain of several devices that amplify, route and process an audio signal for meeting a nominal output level for the listener. 
### Microphone Level

The first step is to convert the source sound into an electrical signal so it can be fed to the rest of the system by using a microphone or playback device. How much voltage does a microphone produce when it's spoken into?

Standard microphones create a very *low-level voltage ranging from as little a 1 mV to 100 mV*.

Since Mic level signals are relatively low, it is normally fed into a mic preamp to boost the signal up to line level. 
### Line Level

Line level signals flow through the sound system after the mic-amplifier stage, and before the amplifier that powers the loudspeakers. Line Level signals are produced at half a volt to one volt, or 750 millivolts. There are two types of audio playback devices that convert sound data into line level signsls. 

Normally, these are audio devices that plug into the *Line IN*, *Aux IN*, and *Line OUT*.
### Speaker Level

After a line level signal enters the amplifier, it transfers to the speakers at speaker level. A loudspeaker requires just a few volts of electrical audio signal to make enough movement in it to create a sound wave that can be heard. 

The size of a speaker does not matter, but typically a larger speaker requires more power than a small one. The higher voltage level (2 to 140V) comes from the amplifier to push it. 
## A True Representation

Sound occurs naturally in analog, as a continuous set of waves that we hear with the human ear. So, when sound is captured in analog, all the possible frequencies and the changes in voltage strength and electrical flow are true representations of the physical disturbances in the air. 

For instance, a soft sound will incur small voltage changes, were loud sounds consist of large changes in voltage. 

Analog recording capabilities can reproduce impressive sounds, with many audio purists preferring the sound of analog signals over digital. However, analog sometimes suffers from noise and nonlinear frequency response problems, which decrease fidelity. 

- For example, each time analog recording are copied, noise will increase.
### Analog Inputs and Outputs

> Understanding the difference between various analog inputs and outputs helps to keep the sound clean, and free of signal loss and noise. 

#### Unbalanced Signals

Cables that carry unbalanced signals have *two conductor wires*. One wire carries the analog audio signal, and is referred to as ***hot***. The other is the ground wire, also called ***earth***, or shield. 

These are acceptable for short runs, but can be susceptible to electrical interference, causing noise. 
Unbalanced cables are terminated with these connector plug ins and jacks:

- RCA (phono jack) with Left (White) and Right (Red)
- Mini Jack 1/8" or 3.5mm Tip-Ring-Sleeve -- TRS
- 1/4" Mono Tip-Sleeve - TS
## A Numerical Representation

> When the original sound is created in analog, the signal will always be interpreted as a wave. Digital sounds, on the other hand, are stored and processed as binary data that represent the sound. 

The waveform is sampled and encoded at evenly-spaced intervals, and therefore will be a series of binary 1's and 0's. How often samples are taken per second is the sampling rate, measured in kHz. With digital encoding, the requirement is to have a sample rate that is at least, at minimum, twice the required frequency range. 

These digital signals have several benefits. Digital signals can carry more information per second than analog signals, and maintain their quality over long distances. 
### Digital Connectors

> Digital audio is made available for AV devices using digital cables. Unlike analog audio cables, which use separate cables for each channel, multiple channels of digital audio can be passed through a single cable.
#### AES/EBU

A digital audio interface for the transmission of stereo or two-channel PCM audio, jointly developed by the ***Audio Engineering Society - AES*** and ***European Broadcasting Union -EBU***

The typical two-channel connector is a 3-pin XLR while eight channels can use a 25-pin connector. 
#### S/PDIF

The ***Sony/Philips Digital Interface (S/PDIF)*** transmits digital audio using either coaxial or optical. While a S/PDIF coaxial connection looks like an RCA analog connector, it is not the same. S/PDIF is a digital audio connector, usually painted orange, making it easier to differentiate from other video connections.

- The fiber optic connection uses a square connector called Toslink (Toshiba Link).
#### HDMI

In addition to digital video, ***High-Definition Multimedia Interface (HDMI)*** can also pass multi-channel high resolution digital audio on a single cable. HDMI technology is used with devices such as Projectors, Blu-ray players, or media players.
#### DisplayPort

***DisplayPort*** is a digital display interface developed by a consortium of PC and chip manufacturers and standardized by VESA. DisplayPort is primarily used to connect video sources to a display device such as a computer monitor, though it can also be used to carry audio, USB and other forms of data.
#### Twisted Pair

Network ***twisted pair*** cabling can carry digital audio over the network, and typically use RJ-45 style connectors. Today's AV applications make use of networked audio as a means for audio distribution.
#### USB-C

***USB Type-C*** offers a small, reversible connector that can be used for charging and transferring audio and video data on laptops, smartphones, and tablets. USB-C connectors can carry more power to charge larger devices, and also support transfer speeds up to 10 Gbps.
### Audio over IP

***Audio over IP (AoIP)*** is the distribution of digital audio across an IP network. With its inherent routing system built into the IP addressing scheme, streams of high-quality audio can be sent over a network to specific devices. 

For example, a microphone preamp with AoIP connectivity can be routed to a specific destination such as an AoIP-enabled processor.

Extron supports audio over the network via the Dante protocol. Dante-equipped products provide scalable audio transport over a local area network using standard IP protocols. Extron offers a full lineup of audio over IP products using the Dante protocol:

- Digital Matrix Processors
- Audio expansion processors
- Audio expansion interfaces
- Audio power amplifiers

> Developed by the Audio Engineering Society, AES67 is an interoperability standard that acts as a translator between Audio over IP protocols. 
# Audio Components

## Recoding Methods

Over the years, there have been many ways to capture sound and play back the audio.
#### Phonograph

> Experiments to record sound on a medium for preservation and reproduction began with the phonograph, invented in 1877. Sound vibration waveforms were engraved onto the surface of a rotating cylinder. Then a playback stylus would trace the vibrating groove reproducing the recorded sound.
#### Vinyl Records

By the late 1920's, the transition from phonograph cylinders to record player turntables had been made as the primary medium for music reproduction. These flat discs have an inscribed spiral groove that starts near the periphery and ends near the center. 

The last part of the spiral meets an earlier part to form a circle. The sound is encoded by variations in the edges of the groove that cause a stylus (needle) placed in it to vibrate at acoustic frequencies when the disc is rotated.

> Although standard record player use declined sharply due to the rise of more portable cassette tapes, some audio enthusiasts believe vinyl fidelity is superior to any other music listening format. 
> 
> With the resurgence of vinyl records, it's possible that an AV system might have a record player, or turntable.
#### Magnetic Tape

Although the first reel-to-reel tape recorded was released in 1935, these were mostly used in radio stations and recording studios. Compact cassette tapes were invented in 1962 as an analog magnetic tape format for audio recording and playback medium. 

Between the early 1970's and the early 2000's, the cassette was one of the two most common formats for prerecorded music, first alongside the vinyl record and then later the digital compact disc - CD.
#### Digital Recording

During the late 1980's, CDs started replacing cassette tapes, holding up to 80 minutes of audio. However, with the advent of Internet-based audio file distribution formats such as MP3, and the popularity of portable audio players, such as mobile phones, CD players are being phased out in favor of minijack auxiliary inputs, wired connections to USB devices, and wireless bluetooth.
## Microphones 

> Can acoustic energy be captured and converted into an electric signal? Yes, a microphone is a *transducer* that converts one form of energy into another, and is normally classified based on how it captures sounds.
### Form Factors

Microphones are available in many form factors as wired or wireless systems, and can be placed in several different locations to capture the most accurate sound possible. One of the most important concepts regarding mic choices is simple: *a stronger signal will be produced the closer the microphone is to the person speaking*.

- ***Boundary***: A small mic capsule mounted flush with a surface, on the floor of a stage, a table in a conference room, or a lectern.
- ***Handheld***: Hand-mics are held in the hand while picking up sound in a variety of settings, on concert stages or a field reporter.
- ***Lavalier***: Lapel mics that allow for hands-free operation typically used in television, theatre and public speaking. Also known as a lav, clip mic, body mic, collar mic or personal mic.
- ***Headset***: A lavalier that brings the mic element closer to the mouth for broadcasting and on-stage lecture presentations. 
- ***Ceiling***: Flush mount or hanging ceiling mics offer directional pickup that delivers clear, intelligible audio without cluttering tabletops.
- ***Desktop***: Usually optimized for speech applications and comes with a stand that securely lets the user position the mic on the surface.
- ***Gooseneck***: A mic stand designed to capture spoken words limited to the speaker, commonly found on podiums or in conference rooms and boardrooms.
### Diaphragm Types

***Dynamic*** microphones use a circular diaphragm that moves back and forth as it reacts to changes in sound pressure. The small coil attached to the back of the diaphragm moves in and out of a magnetic field creating an electrical signal. This design is durable, handles loud sounds very well, and is standard for stage use.

***Condenser*** microphones use a pair of circular plates that require power. One is fixed while the other moves when energized by an acoustic source to create an electrical signal. These generally have a wider/flatter frequency response than dynamic microphones. 

***Ribbon***: microphones use a small metallic ribbon suspended between a magnetic field. These are very fragile, but have a quick transient response. 
### Preamps

Although the microphone plays an important factor in quality of an audio signal, it typically does not output a line level signal. So, the mic will need boosting using a preamp, to increase the audio signal to line level, or the minimum input level for the next stage in the chain. 

The conversion process takes a low electrical signal to an output signal strong enough for further processing or sending to a power amplifier or loudspeaker. 
## Mixers

By inputting the source signals into a mixer, the audio signal can be blended or "mixed" with other signals, the tone can be altered, dynamics processing can be applied, and effects can be added. 

The output signals can then be routed to additional signal processing, recording devices, or amplifiers. Mixers, also known as mixing consoles or sound boards, are mostly used in recording studios, events, or concerts for sound reinforcement, broadcasting, television, and film post-production.
## Gain Controls

The terms 'gain' and 'level' refer to the voltage of the audio signal. 

***Gain*** is the input level of the audio, and volume level is the output. In recording audio, gain adjustment is the first control that the microphone signal goes through a mixer while other levels are adjusted afterwards. Most audio recording and mixing devices include user-accessible gain controls.

Gain, or signal strength, must be maintained throughout the audio system to achieve audio design goals. To maintain signal strength, points of adjustment or ***gain stages*** are established. Proper gain staging is critical in audio. If the signal is too large, or too small, for the next stage in the audio signal path, distortion or noise may result.

Positive gain increases *signal amplitude*, while negative gain reduces *signal amplitude*. The objective with gain adjustments is to maintain the cleanest signal possible through the entire signal chain. 

> ***Analog-to-Digital Conversion*** (ADC) is the process in which analog signals are changed into digital signals. The input into an ADC device consists of an analog voltage, while the output has defined levels in binary strings of 0s and 1s.
## Dynamic Range

> Dynamic range describes the ratio between the smallest and largest signals that can be reproduced by a system. Similarly, the dynamic range of human hearing id the difference between the softest sound we can perceive and the loudest. 

The human ear can generally hear sounds within the frequencies between 20 Hz and 20 kHz. Lower frequencies represent the bass in music. Higher frequencies represent the treble in music.
### The Noise Floor

Any signal other than the intended one is identified as noise. In most environments, there is normally some type of background noise emanating from a source. Related to acoustics, the ambient volume of a room when everything is off and quiet normally has very faint sounds emanating from the HVAC system, a rumble from traffic or hums from nearby equipment. 

Even when sound is processed through audio equipment, the electronics can often introduce static or interference that adds noise to the signal
### Headroom

***Clipping*** is a form of distortion that limits a signal once it exceeds a threshold. This is usually due to the audio signal being overdriven, too loud, into an amplifier or the next stage. For example, 16 bit audio has 65,536 values of loudness. 

- If the sound level is increased beyond 65,536 loudness value, then those levels will clip, that can damage the audio system or signal. 

***Headroom*** is the safety zone allowing audio peaks to exceed the nominal level before clipping will occur. Every audio-passing system has two limits, the quiet end is the ***noise floor*** and the loud end is ***clipping***. 

The distance between the noise floor and headroom is called ***Dynamic Range***. When recording or producing audio, keeping signal levels as high as possible without clipping will maximize the sound quality.
### Digital Signal Processing

Many times, the audio signal must be mixed, changed, routed or adapted to suit the needs of the application or environment. For example, to adjust the resulting output sound, the shape of the signal or changes to its electrical characteristics may be required.

To achieve such changes, devices that manipulate the audio signal in this manner are collectively known as signal processors. Any manipulation of digital bits representing sound information is lumped into the phrase, `Digital Signal Processing - DSP`. 

With algorithms and multiple calculation processes, *DSPs can change the level, timing, and frequency content of an audio signal.* 

***Extron Audio DSP*** systems are able to mix, optimize and fine-tune audio signals. 
##### Extron ProDSP

**Extron ProDSP** is a powerful platform based on a 64-bit floating point technology with an extensive array of digital processing for gain, filtering, dynamics, delay, ducking, loudness, feedback suppression, and select models supporting *Acoustic Echo Cancellation - AEC*
####  Ducking

Background music is often used in a space to create an atmosphere, whether it be upbeat like a sports bar or calming like a spa. However, there may be times where that atmosphere must be disrupted by a page or announcement. With use of a DSP, the level of an audio signal can be set to automatically reduce when the presence of another signal is detected. 

For instance, instead of having a microphone announcement complete with the background music, when the mic signal is detected the music will automatically decrease in level. This level adjustment is called **ducking**.

DSPs are able to automatically attenuate the level of one source in favor of a primary source whenever the primary source is present.  This feature enhances intelligibility by providing a significant audio level between the two sources. 
#### Dynamics

**Dynamic** processing of a DSP will enhance an audio signal by altering the dynamic range:

- ***Automatic Gain Control***: Provides a consistent output signal amplitude despite variation of the input signal amplitude.
- ***Compression***: Reduces the loud sounds or amplifies quiet sounds by narrowing an audio signal's dynamic range. Signals above a set threshold initiate compression, enabling the increase of "average" or "overall" levels. 
- ***Limiting***: A type of compression where an absolute maximum level cannot be exceeded.
- ***Noise Gating***: Sets threshold where signal levels below a set point are attenuated and not passed through the signal chain.
#### Delays

**Delays** can often occur when parallel signal channels require different processing. The ability to adjust the delay settings for one channel versus another is necessary to keep the signal chain in-sync. 

Delay can be used for applications where audio and video signals are processed separately with varying transmission speeds. This causes the audio to arrive before the video, producing lip-sync issues.

Delay is also used for aligning audio sources at different listener distances, deliver proper sound coverage in large areas between diverse loudspeaker locations. When the output from multiple loudspeakers arrive at a listener at differing times, speech intelligibility can be destroyed. By aligning the sources, clear speech and uniform coverage requirements can be met. 
#### Filtering

One of the most common DSP functions is **filtering**. These filters can amplify, pass, or attenuate certain frequency ranges. For example:

- **High Pass**
- **Low Pass**
- **Band Pass**
- **High Shelf**
- **Low Shelf**
- **Notch**
#### Feedback Suppression

When a sound loop exists between an audio input and the output, feedback may occur. For example, as microphone signals are amplified and passed out of a loudspeaker, feedback is heard when the microphone picks up the sound from the loudspeaker and passes it through again.

***Feedback Suppression*** utilizes multiple dynamic notch filters controlled by a DSP to counteract the waves cycling between the mic and loudspeakers. The DSP detects these sensitive frequencies and adjusts the dynamic filter's resonant point to coincide with the offending acoustic oscillation. Most DSP systems employ dynamic and fixed filters that may be adjusted manually or automatically. 
#### Acoustic Echo Cancellation

One of the most active and intense of the DSP routines is ***Acoustic Echo Cancellation - AEC***. AEC eliminates echoes that occur on the "far end" in teleconferencing when a presenter, speaking into the local microphone on the "near end", is transmitted to the far end loudspeaker. 

As the voice amplified into the far-end space, it is picked up by the far-end microphone and sent back to the near-end presenter as an echo of their own voice. 

Without echo cancellation, this effect can make normal conversation impossible. AEC works to prevent this by 'learning' the actual transfer function between the microphone and loudspeaker in the conferencing system. 

Once learned, AEC cancels the near-end talkers voice from being transmitted back from the far end. 
#### Amplifiers

***Amplifiers*** take the input signal and increase the voltage output enough to drive a loudspeaker. For example, the output of a DSP must be amplified before it can produce an audible sound from the loudspeaker. 

- An amplifier can either be a separate piece of equipment or integrated within another device, such as mixer or a switcher. 

All amplifiers have a power rating, called ***Watts***, and an acceptable range of load impedances which are expressed in ***Ohms***. When delivering loudspeaker level audio, it is *vital to match the impedance of the amplifier output to the impedance of the connected loudspeaker system.* 
To determine the amount of actual power needed, it is very helpful to use an amplifier calculator, such as on the Extron website, to determine real power needed.

The amplifier input stage is the circuit that receives and prepares the input signals for amplification. This is typically a 1/4", XLR or captive screw connector. The output stage converts the input signals into a powerful loudspeaker level "replica", then drives it to the loudspeaker. 
#### Using an Amplifier Calculator

All amplifiers have a power rating, called Watts, and an acceptable range of load impedances which are expressed in Ohms. When delivering loudspeaker level audio, it is vital to match the impedance of the amplifier output to the impedance of the connected loudspeaker system.

To determine the amount of actual power needed, it is very helpful to use an amplifier calculator, such as the [Amplifier Power Calculator](https://www.extron.com/calculators/amplifier-power/?tab=tools) on the Extron website.   
  
Click the video below to view a tutorial on Determining Amplifier Power Requirements.
#### Amplifier Considerations

Since there are several types of amplifier classifications, hybrids and combinations, there are some helpful things to know that distinguishes their circuitry design, power conversion, and signal output capabilities. 

It is important to understand some of the different parameters associated with amplifiers, and how they affect their performance. Below are some of the more helpful considerations:

- ***Efficiency*** - the amplifier will consume power during the amplification process, while some power will be lost in the form of heat. The Efficiency of an amplifier is its ability to limit the loss of power during this process.
- ***Distortion***: When signal to the amplifier is increased, the output also increases until a point is reached where the amplifier becomes saturated, and results in Distortion.
- ***Gain***: With amplification, the input and output signal amplitudes are measured. The difference between these two quantities is how much an amplifier "amplifies" the input signal, known as Gain.

| Class | Efficiency  | Distortion | Gain        |
| ----- | ----------- | ---------- | ----------- |
| A     | Low 10-20%  | Low        | Low         |
| B     | Good 70-80% | Medium     | Medium/High |
| AB    | Good 50-60% | Low        | High        |
| C     | High 80%    | High       | High        |
| D     | High 90%    | Low        | High        |
#### Loudspeakers

> The last link of the audio signal path is the ***Loudspeaker***. Loudspeakers operate much like a dynamic microphone in reverse. It's an *electroacoustic transducer that converts electrical audio signals into acoustic energy (sound)*. 

The loudspeaker receives the voltage of the audio signal through loudspeaker wires into an electromagnet coil of copper wire, called a *voice coil*. The signal passing through the voice coils creates a constantly changing magnetic field which interacts with the permanent magnetic field of the loudspeaker magnets. The changing relationship of these two fields causes the cones to be forced outward and pulled back, translating the electrical signal into sound pressure charges that we can hear.

***Extron Loudspeakers*** support a wide variety of needs commonly used in AV systems for ceiling, surface mount, pendant, and large format options. Other loudspeaker technologies exist, but the cone style is the most prevalent. 
#### Parts of a Loudspeaker

The individual transducers in a loudspeaker, referred to as *drivers*, conbvery the electrical audio signals into sound waves. A loudspeaker has several parts, yet an entire system includes the enclosure, sometimes a crossover, and the drivers. 

Enclosures refer to the box or housing, and crossovers divide the incoming signal into the frequency bands that will be handled by the drivers. 

A cutaway view of a typical cone loudspeaker is shown below. 
#### Loudspeaker Measurements

There are many types of loudspeaker sizes for reproducing sound waves over the entire 20 Hz to 20 kHz frequency spectrum. Tweeters are small drivers that produce the highest frequencies with the shortest wavelengths. Woofers are the largest drivers and produce the lowest frequencies with the longest wavelengths. There are also midrange drivers of various sizes that reproduce middle frequencies between the tweeter and woofer.

Loudspeakers are customarily designated as either low- or high-impedance types. 

- Low impedance is a range of 2 to 16 ohms, used in household stereo systems, car audio, night clubs, sporting events concert venues, restaurants and patios. 
- High impedance usually means several-hundred or thousand (k) ohms, commonly referred to as 25V, 70V, or 100V loudspeakers, ideal for public addresses in corporate, comemrical, industrial, retail, airports, or educational applications. 

High impedance speakers are connected to amplifiers of high output impedance; and low impedance loudspeakers to low output impedance amplifiers. 

Ideally, the output impedance of the amplifier should be identical with loudspeaker impedance. Connecting a low impedance speaker to a high output impedance amplifier causes impedance mismatching, resulting in amplifier malfunction, distortion, or damage. 
#### Loudspeaker Placement

Sound management requires some amount of design time in positioning loudspeakers for an audio environment. The patterns for sound waves are conical where the coverage area is based on angles and distance. Consideration should be given to direct versus reflected sound. As the level of direct sound decreases compared to reflected sound, intelligibility is reduced. *Sound pressure drops to 6 dB when the distance from the loudspeaker is doubled.* 

Only listeners positioned directly on the loudspeaker axis realize the full sound. As listener positions vary, a decrease in direct sound and nonlinear off-axis frequency response cause less than optimal sound quality. 

System designers must balance the sound pressure levels between the on-axis "sweet spot" and the reduced performance occurring at distances away from the loudspeaker's center axis. 

The Extron Flat Field Technology reduces the beaming of mid and high frequencies directly under the loudspeaker. This provides a wide room coverage pattern that delivers consistent sound levels across the listening area. 
### Calculating Ceiling Speakers

Since speakers are often tailored for specific applications, their design and performance play a major role in determining their quantities and positioning for proper coverage. 

The [Ceiling Speaker Calculator](https://www.extron.com/calculators/ceiling-speakers/?tab=tools) on the Extron website utilizes the room dimensions, playback content, and allowable variances in sound levels to calculate the number of ceiling speakers required for different room environments.
## Standards and File Formats

### Technical Standards and Legal Definitions

Standards are developed by various organizations to ensure that audio systems and environments adhere to technically valid definitions for setup, recording, encoding, compression, file formatting, compatibility, transmission, and broadcast.
#### SMTPE

***Society of Motion Picture & Television Engineers - SMPTE*** has produced over 800 standards, recommended practices, and engineering guidelines. On average, 50 new standards are generated each year associated with TV production, motion picture filmmaking, digital camera, audio recording, and transmission and broadcast formats. 
#### AES

***Audio Engineering Society - AES*** is a global society devoted exclusively to audio technology. This membership includes engineers and scientists in the professional audio industry, alongside acousticians, audiologists, academics, students and other disciplines related to audio, the development of audio devices and audio content production. The AES organization creates standards for AES digital audio connectors. 
#### CTA 

***Consumer Technology Association - CTA*** is an organization that influences the standards and public policies for consumer electronics, and raises awareness of the virtues for a quality audio experience by defining and explaining audio products for consumers. Members collaborate with the content community to promote a quality audio, and encourage standard setting activities for measuring and reporting performance of audio products.

Standards are developed to test and report the performance of receivers, tuner/pre-amplifiers, amplifiers, loudspeakers and powered subwoofers.
#### IEC

***International Electrotechnical Commission - IEC*** prepares and publishes International Standards for all electrical, electronic, and related technologies, as well as power generation, transmission and distribution, home appliances, office equipment, semiconductors, fiber optics, batteries, solar energy, nanotechnology, marine energy, etc.
#### ISO

***International Organization for Standardization - ISO*** promotes worldwide proprietary, industrial and commercial standards, manufactured products and technology, food safety, agriculture and healthcare. These standards also aid in products and services that are safe, reliable and of good quality. 
#### IEEE

***Institute of Electrical and Electronics Engineers - IEEE*** is the world's largest technical professional organization dedicated to advancing technology through its publications, conferences, technology standards and professional and educational activities. 
#### AVIXA

***Audiovisual and Integrated Experience Association - AVIXA*** members include manufacturers, systems integrators, dealers, distributors, consultants, programmers, rental and staging companies, technology managers, IT professionals, content producers, and multimedia professionals. A leading resource for AV standards, certification, training and market intelligence. 
### Common File Formats

Audio files are used for storing digital audio data. The bit layout of the audio data (excluding metadata) is called the audio coding format and can be uncompressed, or compressed to reduce the file size.

The following audio file types are commonly used in the industry.
#### Waveform File Format - WAV

***WAV*** files are a Microsoft and IBM uncompressed audio file format for storing an audio bit stream on Windows, Mac and Linux systems.

On systems where disk space is not a constraint, such as audio editing or retaining first generation archived files of high quality, these large WAV files are commonly used. 

| Uncompressed | Compressed  |
| ------------ | ----------- |
| WAV          | MPEG        |
| AIFF         | FLAC<br>AAC |
#### Audio Interchange File Format - AIFF

The ***AIFF*** file standard was developed by Apple for use on Macintosh computer systems. The uncompressed file use large amounts of disk space, about 10 MB for one minute of stereo audio at a sample rate of 44.1 kHz and a bit depth of 16 bits.
#### Moving Picture Experts Group - MPEG

***MPEG*** is an ISO standard for digital audio and video encoding. 

***MPEG-1*** includes three layers of audio encoding techniques:

- Audio Layer 1 - MP1 - 382 kb/s
- Audio Layer 2 - MP2 - 192 kb/s stereo
- Audio Layer 3 - MP3 -128 kb/s stereo

***MPEG-2*** 

- Audio Part 3 - Coding of audio with more than two channels, up to 5.1 multichannel
- Audio Part 7 - Multichannel encoding up to 48 channels

***MPEG-3*** are standards for video signals rolled into MPEG-2

***MPEG-4*** is the compression of video and audio digital data, web streaming media, CD distribution, voice (telephone and video), and broadcast television applications.
#### Free Lossless Audio Codec - FLAC

**FLAC** is an audio format similar to MP3, where audio data is compressed without any loss to quality. The fastest and most widely supported lossless audio codec.
#### Advanced Audio Coding - AAC

***AAC*** is an audio coding standard for lossy digital audio compression, that was designed to be the successor of the MP3 format. It achieves better sound quality than MP3 at a similar bit rate, and is the standard audio format for YouTube, iPhone, iPod, iTunes, Nintendo, Playstation and supported on Wii, Sony Walkman, Android, Blackberry, and manufacturers of in-dash car audio systems. 
